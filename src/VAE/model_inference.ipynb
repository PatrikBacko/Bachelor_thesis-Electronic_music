{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "import pyaudio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from models.VAE_1 import VAE_1\n",
    "from utils.prepare_data import pad_or_trim\n",
    "\n",
    "from utils.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVERSE_MFCC_KWARGS = {\n",
    "    'n_mels': MFCC_KWARGS['n_mels'],\n",
    "    'dct_type': MFCC_KWARGS['dct_type'],\n",
    "    'norm': MFCC_KWARGS['norm'],\n",
    "    'lifter': MFCC_KWARGS['lifter'],\n",
    "    'n_fft': MFCC_KWARGS['n_fft'],\n",
    "    'hop_length': MFCC_KWARGS['hop_length'],\n",
    "    'win_length': MFCC_KWARGS['win_length'],\n",
    "    'window':  MFCC_KWARGS['window'],\n",
    "    'center': MFCC_KWARGS['center'],\n",
    "    'pad_mode': MFCC_KWARGS['pad_mode'],\n",
    "    'power': MFCC_KWARGS['power'],\n",
    "\n",
    "    ####\n",
    "    # 'sr': 22050,\n",
    "    ####\n",
    "\n",
    "    'ref': 1.0,\n",
    "    'n_iter': 32,\n",
    "    'length': None,\n",
    "    'dtype': np.float32\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_wave(wave, sr):\n",
    "    # initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # open a stream\n",
    "    stream = p.open(format=pyaudio.paFloat32,\n",
    "                    channels=1,\n",
    "                    rate=sr,\n",
    "                    output=True)\n",
    "\n",
    "    # play audio\n",
    "    stream.write(wave.tobytes())\n",
    "\n",
    "    # stop stream and terminate PyAudio\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random_wave(sample_type, path_to_samples = r\"C:\\Users\\llama\\Desktop\\cuni\\bakalarka\\Bachelor_thesis-Electronic_music\\data\\drums-one_shots\"):\n",
    "    # load random wave\n",
    "    path = os.path.join(path_to_samples, sample_type, f'{sample_type}_samples')\n",
    "\n",
    "    sample_name = np.random.choice(os.listdir(path))\n",
    "    sample, sr = lb.load(os.path.join(path, sample_name))\n",
    "    return sample, sr\n",
    "\n",
    "def convert_to_mfcc(wave, sr):\n",
    "    mfcc = lb.feature.mfcc(y=wave, sr=sr, **MFCC_KWARGS)\n",
    "    return mfcc\n",
    "\n",
    "def convert_to_wave(mfcc, sr):\n",
    "    return lb.feature.inverse.mfcc_to_audio(mfcc=mfcc, sr=sr, **INVERSE_MFCC_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_latent_space(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps*std\n",
    "\n",
    "def fuse_sampled_samples(samples, weights = None):\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(samples)) / len(samples)\n",
    "    return np.average(samples, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_mfcc': 512, 'dct_type': 2, 'norm': 'ortho', 'lifter': 0, 'n_fft': 512, 'hop_length': 256, 'win_length': 512, 'window': 'hann', 'center': True, 'pad_mode': 'constant', 'power': 2.0, 'n_mels': 256, 'fmin': 0.0, 'fmax': None, 'htk': False, 'dtype': <class 'numpy.float32'>}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\llama\\Desktop\\cuni\\bakalarka\\Bachelor_thesis-Electronic_music')\n",
    "\n",
    "\n",
    "model_dir_path = Path(r'C:\\Users\\llama\\Desktop\\cuni\\bakalarka\\Bachelor_thesis-Electronic_music\\trained_models\\model_test_4')\n",
    "model_name = os.path.basename(model_dir_path)[6:]\n",
    "config = load_config(model_dir_path / f'{model_name}_config.pkl')\n",
    "\n",
    "print(config.mfcc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave, sr = load_random_wave('clap')\n",
    "x = pad_or_trim(convert_to_mfcc(wave, sr), length=100)\n",
    "\n",
    "\n",
    "reconstructed_x, mu, logvar = model(torch.tensor(x).view(1, 1, *x.shape))\n",
    "\n",
    "reconstructed_wave = convert_to_wave(reconstructed_x.detach().numpy().reshape(-1, 100), sr)\n",
    "\n",
    "sampled_x = model.decoder.forward(sample_from_latent_space(mu, logvar))\n",
    "\n",
    "play_wave(wave, sr)\n",
    "play_wave(reconstructed_wave, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

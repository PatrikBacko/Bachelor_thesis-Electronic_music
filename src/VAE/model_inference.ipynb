{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "import pyaudio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from models.VAE_1 import VAE_1\n",
    "from utils.prepare_data import pad_or_trim\n",
    "\n",
    "from utils.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVERSE_MFCC_KWARGS = {\n",
    "    'n_mels': MFCC_KWARGS['n_mels'],\n",
    "    'dct_type': MFCC_KWARGS['dct_type'],\n",
    "    'norm': MFCC_KWARGS['norm'],\n",
    "    'lifter': MFCC_KWARGS['lifter'],\n",
    "    'n_fft': MFCC_KWARGS['n_fft'],\n",
    "    'hop_length': MFCC_KWARGS['hop_length'],\n",
    "    'win_length': MFCC_KWARGS['win_length'],\n",
    "    'window':  MFCC_KWARGS['window'],\n",
    "    'center': MFCC_KWARGS['center'],\n",
    "    'pad_mode': MFCC_KWARGS['pad_mode'],\n",
    "    'power': MFCC_KWARGS['power'],\n",
    "\n",
    "    ####\n",
    "    # 'sr': 22050,\n",
    "    ####\n",
    "\n",
    "    'ref': 1.0,\n",
    "    'n_iter': 32,\n",
    "    'length': None,\n",
    "    'dtype': np.float32\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_wave(wave, sr):\n",
    "    # initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # open a stream\n",
    "    stream = p.open(format=pyaudio.paFloat32,\n",
    "                    channels=1,\n",
    "                    rate=sr,\n",
    "                    output=True)\n",
    "\n",
    "    # play audio\n",
    "    stream.write(wave.tobytes())\n",
    "\n",
    "    # stop stream and terminate PyAudio\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random_wave(sample_type, path_to_samples = r\"C:\\Users\\llama\\Desktop\\cuni\\bakalarka\\Bachelor_thesis-Electronic_music\\data\\drums-one_shots\"):\n",
    "    # load random wave\n",
    "    path = os.path.join(path_to_samples, sample_type, f'{sample_type}_samples')\n",
    "\n",
    "    sample_name = np.random.choice(os.listdir(path))\n",
    "    sample, sr = lb.load(os.path.join(path, sample_name))\n",
    "    return sample, sr\n",
    "\n",
    "def convert_to_mfcc(wave, sr):\n",
    "    mfcc = lb.feature.mfcc(y=wave, sr=sr, **MFCC_KWARGS)\n",
    "    return mfcc\n",
    "\n",
    "def convert_to_wave(mfcc, sr):\n",
    "    return lb.feature.inverse.mfcc_to_audio(mfcc=mfcc, sr=sr, **INVERSE_MFCC_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_latent_space(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps*std\n",
    "\n",
    "def fuse_sampled_samples(samples, weights = None):\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(samples)) / len(samples)\n",
    "    return np.average(samples, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\llama\\\\Desktop\\\\cuni\\\\bakalarka\\\\Bachelor_thesis-Electronic_music\\\\trained_models\\\\all_latent-dims=2_noise=multiplicative\\\\all_latent-dims=2_noise=multiplicative_config.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_dir_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mllama\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcuni\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbakalarka\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBachelor_thesis-Electronic_music\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrained_models\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mall_latent-dims=2_noise=multiplicative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(model_dir_path)\n\u001b[1;32m----> 3\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(model_dir_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_config.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\llama\\Desktop\\cuni\\bakalarka\\Bachelor_thesis-Electronic_music\\src\\VAE\\utils\\config.py:103\u001b[0m, in \u001b[0;36mload_config\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    101\u001b[0m print('MFCC conversion kwargs:', file=config_file)\n\u001b[0;32m    102\u001b[0m print(f'\\tMFCC kwargs: {mfcc_kwargs}', file=config_file)\n\u001b[1;32m--> 103\u001b[0m print('******************', file=config_file)\n\u001b[0;32m    104\u001b[0m print('machine readable config saved also to .pkl file')\n\u001b[0;32m    105\u001b[0m \n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\llama\\\\Desktop\\\\cuni\\\\bakalarka\\\\Bachelor_thesis-Electronic_music\\\\trained_models\\\\all_latent-dims=2_noise=multiplicative\\\\all_latent-dims=2_noise=multiplicative_config.pkl'"
     ]
    }
   ],
   "source": [
    "model_dir_path = Path(r'C:\\Users\\llama\\Desktop\\cuni\\bakalarka\\Bachelor_thesis-Electronic_music\\trained_models\\all_latent-dims=2_noise=multiplicative')\n",
    "model_name = os.path.basename(model_dir_path)\n",
    "config = load_config(model_dir_path / f'{model_name}_config.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave, sr = load_random_wave('clap')\n",
    "x = pad_or_trim(convert_to_mfcc(wave, sr), length=100)\n",
    "\n",
    "\n",
    "reconstructed_x, mu, logvar = model(torch.tensor(x).view(1, 1, *x.shape))\n",
    "\n",
    "reconstructed_wave = convert_to_wave(reconstructed_x.detach().numpy().reshape(-1, 100), sr)\n",
    "\n",
    "sampled_x = model.decoder.forward(sample_from_latent_space(mu, logvar))\n",
    "\n",
    "play_wave(wave, sr)\n",
    "play_wave(reconstructed_wave, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

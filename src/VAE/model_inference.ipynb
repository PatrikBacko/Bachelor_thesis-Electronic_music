{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "import pyaudio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from VAE_1 import VAE_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_wave(wave, sr):\n",
    "    # initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # open a stream\n",
    "    stream = p.open(format=pyaudio.paFloat32,\n",
    "                    channels=1,\n",
    "                    rate=sr,\n",
    "                    output=True)\n",
    "\n",
    "    # play audio\n",
    "    stream.write(wave.tobytes())\n",
    "\n",
    "    # stop stream and terminate PyAudio\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_1(32)\n",
    "model.load_state_dict(torch.load('model_1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, mu, logvar):\n",
    "    model.eval()\n",
    "    z = model.reparameterize(mu, torch.tensor(logvar*2))\n",
    "    with torch.no_grad():\n",
    "        return model.decoder(z)\n",
    "    \n",
    "reconstructed_x = inference(model, torch.zeros((32)), torch.ones((32)))\n",
    "\n",
    "reconstructed_x_np = reconstructed_x[0,0,:,:].numpy()\n",
    "\n",
    "lb.display.specshow(reconstructed_x_np, sr = 44100)\n",
    "\n",
    "inverted = lb.feature.inverse.mfcc_to_audio(reconstructed_x_np, sr=44100, n_mels=256, n_fft=512, hop_length=256, lifter=0, dct_type=3)\n",
    "play_wave(inverted, 44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_random_sample(sample_type, paths_to_samples = ):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_SHAPE = 1, 1, 256, 100\n",
    "INVERSE_MFCC_PARAMS = {\n",
    "    'sr': 44100,\n",
    "    'n_mels': 256,\n",
    "    'n_fft': 512,\n",
    "    'hop_length': 256,\n",
    "    'lifter': 0,\n",
    "    'dct_type': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick = torch.from_numpy(mfccs[0]).view(1, 1, 256,100)\n",
    "\n",
    "\n",
    "print(kick.shape)\n",
    "\n",
    "reconstructed_x, mu, logvar = model.forward(kick)\n",
    "\n",
    "reconstructed_x_np = reconstructed_x[0,0,:,:].detach().numpy()[:,:-2]\n",
    "\n",
    "\n",
    "lb.display.specshow(reconstructed_x_np, sr = 44100)\n",
    "\n",
    "\n",
    "\n",
    "inverted_orig = lb.feature.inverse.mfcc_to_audio(mfccs[0], sr=44100, n_mels=256, n_fft=512, hop_length=256, lifter=0, dct_type=3)\n",
    "inverted = lb.feature.inverse.mfcc_to_audio(reconstructed_x_np, sr=44100, n_mels=256, n_fft=512, hop_length=256, lifter=0, dct_type=3)\n",
    "\n",
    "play_wave(inverted_orig, 44100)\n",
    "play_wave(inverted, 44100)\n",
    "\n",
    "reconstructed_x = inference(model, mu + 1, logvar + 0.5)\n",
    "reconstructed_x_np = reconstructed_x[0,0,:,:].detach().numpy()[:,:-2]\n",
    "\n",
    "inverted = lb.feature.inverse.mfcc_to_audio(reconstructed_x_np, sr=44100, n_mels=256, n_fft=512, hop_length=256, lifter=0, dct_type=3)\n",
    "lb.display.specshow(reconstructed_x_np, sr = 44100)\n",
    "\n",
    "play_wave(inverted, 44100)\n",
    "\n",
    "print(np.mean(mu.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\llama\\AppData\\Local\\Temp\\ipykernel_12592\\4034893152.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = model.reparameterize(mu, torch.tensor(logvar*2))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def mfcc_to_wave(mfcc):\n",
    "    wave = lb.feature.inverse.mfcc_to_audio(mfcc, **INVERSE_MFCC_PARAMS)\n",
    "    return wave\n",
    "\n",
    "kick_1_np = mfccs[20]\n",
    "kick_1_torch = torch.from_numpy(kick_1_np).view(*VIEW_SHAPE)\n",
    "kick_1_reconstructed, kick_1_mu, kick_1_logvar = model.forward(kick_1_torch)\n",
    "\n",
    "kick_2_np = mfccs[-13]\n",
    "kick_2_torch = torch.from_numpy(kick_2_np).view(*VIEW_SHAPE)\n",
    "kick_2_reconstructed, kick_2_mu, kick_2_logvar = model.forward(kick_2_torch)\n",
    "\n",
    "interpolated_mu = (kick_1_mu + kick_2_mu) / 2\n",
    "interpolated_logvar = (kick_1_logvar + kick_2_logvar) / 2\n",
    "\n",
    "reconstructed_interpolation = inference(model, interpolated_mu, interpolated_logvar)\n",
    "# The :, :-2 indexing is because of the reconstruction after padding.\n",
    "reconstructed_interpolation_np = reconstructed_interpolation[0, 0, :, :].detach().numpy()[:, :-2]\n",
    "reconstructed_interpolation_wave = mfcc_to_wave(reconstructed_interpolation_np)\n",
    "\n",
    "\n",
    "play_wave(mfcc_to_wave(kick_1_np), INVERSE_MFCC_PARAMS['sr'])\n",
    "play_wave(mfcc_to_wave(kick_2_np), INVERSE_MFCC_PARAMS['sr']) \n",
    "play_wave(reconstructed_interpolation_wave, INVERSE_MFCC_PARAMS['sr'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "import pyaudio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from models.VAE_1 import VAE_1\n",
    "from utils.prepare_data import MFCC_KWARGS, pad_or_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVERSE_MFCC_KWARGS = {\n",
    "    'n_mels': MFCC_KWARGS['n_mels'],\n",
    "    'dct_type': MFCC_KWARGS['dct_type'],\n",
    "    'norm': MFCC_KWARGS['norm'],\n",
    "    'lifter': MFCC_KWARGS['lifter'],\n",
    "    'n_fft': MFCC_KWARGS['n_fft'],\n",
    "    'hop_length': MFCC_KWARGS['hop_length'],\n",
    "    'win_length': MFCC_KWARGS['win_length'],\n",
    "    'window':  MFCC_KWARGS['window'],\n",
    "    'center': MFCC_KWARGS['center'],\n",
    "    'pad_mode': MFCC_KWARGS['pad_mode'],\n",
    "    'power': MFCC_KWARGS['power'],\n",
    "\n",
    "    ####\n",
    "    # 'sr': 22050,\n",
    "    ####\n",
    "\n",
    "    'ref': 1.0,\n",
    "    'n_iter': 32,\n",
    "    'length': None,\n",
    "    'dtype': np.float32\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_wave(wave, sr):\n",
    "    # initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # open a stream\n",
    "    stream = p.open(format=pyaudio.paFloat32,\n",
    "                    channels=1,\n",
    "                    rate=sr,\n",
    "                    output=True)\n",
    "\n",
    "    # play audio\n",
    "    stream.write(wave.tobytes())\n",
    "\n",
    "    # stop stream and terminate PyAudio\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: load config (keď prerobím config files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "model = VAE_1(latent_dim)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\llama\\Desktop\\cuni\\bakalarka\\Bachelor_thesis-Electronic_music\\trained_models\\all_latent-dims=2_noise=multiplicative\\model_all_latent-dims=2_noise=multiplicative.pkl', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random_wave(sample_type, path_to_samples = r\"C:\\Users\\llama\\Desktop\\cuni\\bakalarka\\Bachelor_thesis-Electronic_music\\data\\drums-one_shots\"):\n",
    "    # load random wave\n",
    "    path = os.path.join(path_to_samples, sample_type, f'{sample_type}_samples')\n",
    "\n",
    "    sample_name = np.random.choice(os.listdir(path))\n",
    "    sample, sr = lb.load(os.path.join(path, sample_name))\n",
    "    return sample, sr\n",
    "\n",
    "def convert_to_mfcc(wave, sr):\n",
    "    mfcc = lb.feature.mfcc(y=wave, sr=sr, **MFCC_KWARGS)\n",
    "    return mfcc\n",
    "\n",
    "def convert_to_wave(mfcc, sr):\n",
    "    return lb.feature.inverse.mfcc_to_audio(mfcc=mfcc, sr=sr, **INVERSE_MFCC_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_latent_space(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps*std\n",
    "\n",
    "def fuse_sampled_samples(samples, weights = None):\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(samples)) / len(samples)\n",
    "    return np.average(samples, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave, sr = load_random_wave('clap')\n",
    "x = pad_or_trim(convert_to_mfcc(wave, sr), length=100)\n",
    "\n",
    "\n",
    "reconstructed_x, mu, logvar = model(torch.tensor(x).view(1, 1, *x.shape))\n",
    "\n",
    "reconstructed_wave = convert_to_wave(reconstructed_x.detach().numpy().reshape(-1, 100), sr)\n",
    "\n",
    "sampled_x = model.decoder.forward(sample_from_latent_space(mu, logvar))\n",
    "\n",
    "play_wave(wave, sr)\n",
    "play_wave(reconstructed_wave, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
